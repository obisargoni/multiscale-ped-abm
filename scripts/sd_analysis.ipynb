{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c58ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime as dt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.append(\".\\\\sample\")\n",
    "from SALibRepastParams import num_levels, params, random_seed, init_problem, calc_second_order, policies\n",
    "\n",
    "import batch_data_utils as bd_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c0ffeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\".//config.json\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6594d212",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_datetime_string = config['file_datetime_string']\n",
    "vehicle_density_timestamp = config['vehicle_density_timestamp']\n",
    "setting = config['setting']\n",
    "\n",
    "gis_data_dir = os.path.abspath(\"..\\\\data\\\\model_gis_data\")\n",
    "data_dir = config['batch_data_dir']\n",
    "img_dir = \"..\\\\output\\\\img\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc432e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_paths = bd_utils.get_ouput_paths(file_datetime_string, vehicle_density_timestamp, data_dir)\n",
    "output_sd_data = output_paths[\"output_sd_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86645e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\obisargoni\\\\eclipse-workspace\\\\repastInterSim\\\\output\\\\batch\\\\model_run_data\\\\metrics_for_sd_analysis.2022.Apr.21.14_56_46.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af6185a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDD = pd.read_csv(output_sd_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbec6a7",
   "metadata": {},
   "source": [
    "## Analyse using tools in ema workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2e74ae",
   "metadata": {},
   "source": [
    "# Sensitivity analysis of distance and crossing location entropy outputs\n",
    "\n",
    "Determining which parameters outcomes are most sensitive to in each policy setting by calculating Sobol indices.\n",
    "\n",
    "Also evaluating which parameter values lead to which outcome values using a regression tree model. Also demonstrating that parameters have non linear effect on outcomes by attempting to fit linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "146e5dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split # for splitting the data into train and test samples\n",
    "from sklearn.metrics import classification_report # for model evaluation metrics\n",
    "from sklearn import tree, linear_model # for decision tree models\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "import graphviz # for plotting decision tree graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e13e2684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitting(X, y, feature_names, criterion, splitter, mdepth, clweight, minleaf):\n",
    "\n",
    "    # Fit the model\n",
    "    model = tree.DecisionTreeRegressor(criterion=criterion, \n",
    "                                        splitter=splitter, \n",
    "                                        max_depth=mdepth,\n",
    "                                        min_samples_leaf=minleaf, \n",
    "                                        random_state=0, \n",
    "                                  )\n",
    "    clf = model.fit(X, y)\n",
    "\n",
    "    # Predict class labels on training data\n",
    "    pred_labels_tr = model.predict(X)\n",
    "\n",
    "    # Tree summary and model evaluation metrics\n",
    "    print('*************** Tree Summary ***************')\n",
    "    print('Tree Depth: ', clf.tree_.max_depth)\n",
    "    print('No. of leaves: ', clf.tree_.n_leaves)\n",
    "    print('No. of features: ', clf.n_features_in_)\n",
    "    print('--------------------------------------------------------')\n",
    "    print(\"\")\n",
    "    \n",
    "    print('*************** Evaluation on Training Data ***************')\n",
    "    score_tr = model.score(X, y)\n",
    "    print('Accuracy Score: ', score_tr)\n",
    "    print('--------------------------------------------------------')\n",
    "    \n",
    "    # Use graphviz to plot the tree\n",
    "    dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                                feature_names=feature_names, \n",
    "                                class_names=None,\n",
    "                                filled=True, \n",
    "                                rounded=True, \n",
    "                                #rotate=True,\n",
    "                               ) \n",
    "    graph = graphviz.Source(dot_data)\n",
    "    \n",
    "    # Return relevant data for chart plotting\n",
    "    return X, y, clf, graph\n",
    "\n",
    "def fitting_linear_regression(X, y, feature_names):\n",
    "\n",
    "    # Fit the model\n",
    "    model = linear_model.LinearRegression( fit_intercept=True)\n",
    "    clf = model.fit(X, y)\n",
    "    \n",
    "    print('*************** Evaluation on Training Data ***************')\n",
    "    score_tr = model.score(X, y)\n",
    "    print('Accuracy Score: ', score_tr)\n",
    "    print('--------------------------------------------------------')\n",
    "    \n",
    "    # Return relevant data for chart plotting\n",
    "    return X, y, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d4e32afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree settings\n",
    "criterion = 'squared_error'\n",
    "splitter = 'best'\n",
    "mdepth = 5\n",
    "clweight = None\n",
    "minleaf = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1c130112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Policy Param = False\n",
      "\n",
      "*************** Tree Summary ***************\n",
      "Tree Depth:  5\n",
      "No. of leaves:  14\n",
      "No. of features:  8\n",
      "--------------------------------------------------------\n",
      "\n",
      "*************** Evaluation on Training Data ***************\n",
      "Accuracy Score:  0.8664076220221705\n",
      "--------------------------------------------------------\n",
      "\n",
      "Policy Param = True\n",
      "\n",
      "*************** Tree Summary ***************\n",
      "Tree Depth:  5\n",
      "No. of leaves:  13\n",
      "No. of features:  8\n",
      "--------------------------------------------------------\n",
      "\n",
      "*************** Evaluation on Training Data ***************\n",
      "Accuracy Score:  0.9524610708916782\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_results = {}\n",
    "grouped = dfDD.groupby([policy_param])\n",
    "for i, (pv) in enumerate(grouped.groups.keys()):\n",
    "    print(\"\\nPolicy Param = {}\\n\".format(pv))\n",
    "    df_exp = grouped.get_group((pv))\n",
    "    \n",
    "    data_dict = df_exp.loc[:, problem['names']].to_dict('records')\n",
    "    vec = DictVectorizer()  # create the DictVectorizer object\n",
    "    vec_array = vec.fit_transform(data_dict).toarray()  # execute process on the record dictionaries and transform the result into a numpy array object\n",
    "    \n",
    "    X, y, clf, graph = fitting(vec_array, df_exp['cross_entropy'].values, vec.get_feature_names_out(), criterion, splitter, mdepth, clweight, minleaf)\n",
    "    model_results[pv] = {'X':X, 'y':y, 'clf':clf, 'graph':graph}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be9de01",
   "metadata": {},
   "source": [
    "Inspect the regression tree results for the different policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "df448818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\output\\\\img\\\\tree_cle_informal.png'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_informal = model_results[1]['graph']\n",
    "graph_informal.format='png'\n",
    "graph_informal.render(filename='tree_cle_informal', directory=img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "697ed507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\output\\\\img\\\\tree_cle_no_informal.png'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_no_informal = model_results[0]['graph']\n",
    "graph_informal.format='png'\n",
    "graph_informal.render(filename=\"tree_cle_no_informal\", directory=img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9551e5c9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obisargoni\\.conda\\envs\\gforge\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>addPedTicks</th>\n",
       "      <th>addVehicleTicks</th>\n",
       "      <th>alpha</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>lambda</th>\n",
       "      <th>minCrossing</th>\n",
       "      <th>tacticalPlanHorizon</th>\n",
       "      <th>timeThreshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084830</td>\n",
       "      <td>0.223881</td>\n",
       "      <td>0.135178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.548266</td>\n",
       "      <td>0.007845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.009338</td>\n",
       "      <td>0.460633</td>\n",
       "      <td>0.159554</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.368865</td>\n",
       "      <td>0.000158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   addPedTicks  addVehicleTicks     alpha   epsilon    lambda  minCrossing  \\\n",
       "0          0.0         0.000000  0.084830  0.223881  0.135178     0.000000   \n",
       "1          0.0         0.001109  0.009338  0.460633  0.159554     0.000343   \n",
       "\n",
       "   tacticalPlanHorizon  timeThreshold  \n",
       "0             0.548266       0.007845  \n",
       "1             0.368865       0.000158  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare feature importances, do these match up with sensitivity indices?\n",
    "clf_inf = model_results[0]['clf']\n",
    "clf_no_inf = model_results[1]['clf']\n",
    "fis = [clf_inf.feature_importances_, clf_no_inf.feature_importances_]\n",
    "\n",
    "dfF = pd.DataFrame(fis, columns = vec.get_feature_names())\n",
    "dfF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd75f57a",
   "metadata": {},
   "source": [
    "Repeat for the distance travelled metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "07125f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Policy Param = False\n",
      "\n",
      "*************** Tree Summary ***************\n",
      "Tree Depth:  5\n",
      "No. of leaves:  11\n",
      "No. of features:  8\n",
      "--------------------------------------------------------\n",
      "\n",
      "*************** Evaluation on Training Data ***************\n",
      "Accuracy Score:  0.737439419707025\n",
      "--------------------------------------------------------\n",
      "\n",
      "Policy Param = True\n",
      "\n",
      "*************** Tree Summary ***************\n",
      "Tree Depth:  5\n",
      "No. of leaves:  12\n",
      "No. of features:  8\n",
      "--------------------------------------------------------\n",
      "\n",
      "*************** Evaluation on Training Data ***************\n",
      "Accuracy Score:  0.5349548076118277\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_results = {}\n",
    "grouped = dfDD.groupby([policy_param])\n",
    "for i, (pv) in enumerate(grouped.groups.keys()):\n",
    "    print(\"\\nPolicy Param = {}\\n\".format(pv))\n",
    "    df_exp = grouped.get_group((pv))\n",
    "    \n",
    "    data_dict = df_exp.loc[:, problem['names']].to_dict('records')\n",
    "    vec = DictVectorizer()  # create the DictVectorizer object\n",
    "    vec_array = vec.fit_transform(data_dict).toarray()  # execute process on the record dictionaries and transform the result into a numpy array object\n",
    "    \n",
    "    X, y, clf, graph = fitting(vec_array, df_exp['DistPAPed'].values, vec.get_feature_names_out(), criterion, splitter, mdepth, clweight, minleaf)\n",
    "    model_results[pv] = {'X':X, 'y':y, 'clf':clf, 'graph':graph}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5ad1dcb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>addPedTicks</th>\n",
       "      <th>addVehicleTicks</th>\n",
       "      <th>alpha</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>lambda</th>\n",
       "      <th>minCrossing</th>\n",
       "      <th>tacticalPlanHorizon</th>\n",
       "      <th>timeThreshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.411590</td>\n",
       "      <td>0.003010</td>\n",
       "      <td>0.559996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018366</td>\n",
       "      <td>0.004553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.753566</td>\n",
       "      <td>0.064177</td>\n",
       "      <td>0.145104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   addPedTicks  addVehicleTicks     alpha   epsilon    lambda  minCrossing  \\\n",
       "0     0.002485              0.0  0.411590  0.003010  0.559996          0.0   \n",
       "1     0.000000              0.0  0.753566  0.064177  0.145104          0.0   \n",
       "\n",
       "   tacticalPlanHorizon  timeThreshold  \n",
       "0             0.018366       0.004553  \n",
       "1             0.000000       0.037153  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare feature importances, do these match up with sensitivity indices?\n",
    "clf_inf = model_results[0]['clf']\n",
    "clf_no_inf = model_results[1]['clf']\n",
    "fis = [clf_inf.feature_importances_, clf_no_inf.feature_importances_]\n",
    "\n",
    "dfF = pd.DataFrame(fis, columns = vec.get_feature_names_out())\n",
    "dfF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "781c2a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\output\\\\img\\\\tree_dist_informal.png'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_informal = model_results[1]['graph']\n",
    "graph_informal.format='png'\n",
    "graph_informal.render(filename='tree_dist_informal', directory=img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "abd01cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\output\\\\img\\\\tree_dist_no_informal.png'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_no_informal = model_results[0]['graph']\n",
    "graph_informal.format='png'\n",
    "graph_informal.render(filename=\"tree_dist_no_informal\", directory=img_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa71744",
   "metadata": {},
   "source": [
    "### Linear regression model just to check whether model is non-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dad2af6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Metric = DistPAPed\n",
      "\n",
      "Policy Param = False\n",
      "*************** Evaluation on Training Data ***************\n",
      "Accuracy Score:  0.3239135581711081\n",
      "--------------------------------------------------------\n",
      "\n",
      "\n",
      "Metric = DistPAPed\n",
      "\n",
      "Policy Param = True\n",
      "*************** Evaluation on Training Data ***************\n",
      "Accuracy Score:  0.4933043983789418\n",
      "--------------------------------------------------------\n",
      "\n",
      "\n",
      "Metric = cross_entropy\n",
      "\n",
      "Policy Param = False\n",
      "*************** Evaluation on Training Data ***************\n",
      "Accuracy Score:  0.5810232299852874\n",
      "--------------------------------------------------------\n",
      "\n",
      "\n",
      "Metric = cross_entropy\n",
      "\n",
      "Policy Param = True\n",
      "*************** Evaluation on Training Data ***************\n",
      "Accuracy Score:  0.662619319269176\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "metrics = ['DistPAPed', 'cross_entropy']\n",
    "dist_model_results = {}\n",
    "grouped = dfDD.groupby([policy_param])\n",
    "for metric in metrics:\n",
    "    for i, (pv) in enumerate(grouped.groups.keys()):\n",
    "        print(\"\\n\\nMetric = {}\".format(metric))\n",
    "        print(\"\\nPolicy Param = {}\".format(pv))\n",
    "        df_exp = grouped.get_group((pv))\n",
    "        data_dict = df_exp.loc[:, problem['names']].to_dict('records')\n",
    "        vec = DictVectorizer()  # create the DictVectorizer object\n",
    "        vec_array = vec.fit_transform(data_dict).toarray()  # execute process on the record dictionaries and transform the result into a numpy array object\n",
    "        X, y, clf = fitting_linear_regression(vec_array, df_exp[metric].values, vec.get_feature_names_out())\n",
    "        dist_model_results[pv] = {'X':X, 'y':y, 'clf':clf, 'graph':graph}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcb7e42",
   "metadata": {},
   "source": [
    "#### Explaining these results\n",
    "\n",
    "When agetns minimise numbers of crossings get more ordered crossing locations. This can be explained by agents crossing less frequently, specifically it appears that the types or crossings that get cut out are those in mid block locations since these are more avoidable than crossing at the end of a block, which will tend to be in the same location for many agents.\n",
    "\n",
    "This pattern may not be reproduced for the grid world since in this case entropy is not so sensitive to the MC parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2134e522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
